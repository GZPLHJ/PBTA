# Ultralytics YOLO ğŸš€, GPL-3.0 license

import torch
import torch.nn as nn
import torch.nn.functional as F

from .metrics import bbox_iou
from .tal import bbox2dist


class FocalLoss(nn.Module):
    def __init__(self, alpha=[0.5,1,1], gamma=2, num_classes=3, size_average=True):
        """
        focal_lossæŸå¤±å‡½æ•°, -Î±(1-yi)**Î³ *ce_loss(xi,yi)
        æ­¥éª¤è¯¦ç»†çš„å®ç°äº† focal_lossæŸå¤±å‡½æ•°.
        :param alpha:   é˜¿å°”æ³•Î±,ç±»åˆ«æƒé‡.      å½“Î±æ˜¯åˆ—è¡¨æ—¶,ä¸ºå„ç±»åˆ«æƒé‡,å½“Î±ä¸ºå¸¸æ•°æ—¶,ç±»åˆ«æƒé‡ä¸º[Î±, 1-Î±, 1-Î±, ....],å¸¸ç”¨äº ç›®æ ‡æ£€æµ‹ç®—æ³•ä¸­æŠ‘åˆ¶èƒŒæ™¯ç±» , retainnetä¸­è®¾ç½®ä¸º0.25
        :param gamma:   ä¼½é©¬Î³,éš¾æ˜“æ ·æœ¬è°ƒèŠ‚å‚æ•°. retainnetä¸­è®¾ç½®ä¸º2
        :param num_classes:     ç±»åˆ«æ•°é‡
        :param size_average:    æŸå¤±è®¡ç®—æ–¹å¼,é»˜è®¤å–å‡å€¼
        """
        super(FocalLoss, self).__init__()
        self.size_average = size_average
        if alpha is None:
            self.alpha = torch.ones(num_classes)
        elif isinstance(alpha, list):
            assert len(alpha) == num_classes  # Î±å¯ä»¥ä»¥listæ–¹å¼è¾“å…¥,size:[num_classes] ç”¨äºå¯¹ä¸åŒç±»åˆ«ç²¾ç»†åœ°èµ‹äºˆæƒé‡
            self.alpha = torch.Tensor(alpha)
        else:
            assert alpha < 1  # å¦‚æœÎ±ä¸ºä¸€ä¸ªå¸¸æ•°,åˆ™é™ä½ç¬¬ä¸€ç±»çš„å½±å“,åœ¨ç›®æ ‡æ£€æµ‹ä¸­ç¬¬ä¸€ç±»ä¸ºèƒŒæ™¯ç±»
            self.alpha = torch.zeros(num_classes)
            self.alpha[0] += alpha
            self.alpha[1:] += (1 - alpha)  # Î± æœ€ç»ˆä¸º [ Î±, 1-Î±, 1-Î±, 1-Î±, 1-Î±, ...] size:[num_classes]

        self.gamma = gamma

        # print('Focal Loss:')
        # print('    Alpha = {}'.format(self.alpha))
        # print('    Gamma = {}'.format(self.gamma))

    def forward(self, preds, labels):
        preds = preds.view(-1, preds.size(-1))
        alpha = self.alpha.to(preds.device)
        labels = labels.to(preds.device)
        labels = labels.to(torch.int64)
        preds_logsoft = F.log_softmax(preds, dim=1)
        preds_softmax = torch.exp(preds_logsoft)
        preds_softmax = preds_softmax.gather(1, labels.view(-1, 1))
        preds_logsoft = preds_logsoft.gather(1, labels.view(-1, 1))

        alpha = alpha.gather(0, labels.view(-1))
        loss = -torch.mul(torch.pow((1 - preds_softmax), self.gamma), preds_logsoft)

        loss = torch.mul(alpha, loss.t())
        if self.size_average:
            loss = loss.mean()
        else:
            loss = loss.sum()
        return loss

class VarifocalLoss(nn.Module):
    # Varifocal loss by Zhang et al. https://arxiv.org/abs/2008.13367
    def __init__(self):
        super().__init__()

    def forward(self, pred_score, gt_score, label, alpha=[0.75,1,1], gamma=2.0):
        weight = alpha * pred_score.sigmoid().pow(gamma) * (1 - label) + gt_score * label
        with torch.cuda.amp.autocast(enabled=False):
            loss = (F.binary_cross_entropy_with_logits(pred_score.float(), gt_score.float(), reduction='none') *
                    weight).sum()
        return loss


class BboxLoss(nn.Module):

    def __init__(self, reg_max, use_dfl=False):
        super().__init__()
        self.reg_max = reg_max
        self.use_dfl = use_dfl

    def forward(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):
        # IoU loss
        weight = torch.masked_select(target_scores.sum(-1), fg_mask).unsqueeze(-1)

        #åŸyolov8ä»£ç 
        # iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True)
        # loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum

        #focal eiou loss1 è¿™ä¸ªæ›´åé‡äºè·å¾—æ˜“åˆ†æ ·æœ¬
        # iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, EIoU=True, Focal=True)
        # if type(iou) is tuple:
        #     loss_iou = ((1.0 - iou[0]) * iou[1].detach() * weight).sum() / target_scores_sum
        # else:
        #     loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum

        #focal eiou loss1 è¿™ä¸ªæ›´åé‡äºè·å¾—éš¾åˆ†æ ·æœ¬
        iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False,CIoU=True,)
        '''
         if type(iou) is tuple:
            loss_iou = ((1.0 - iou[0]) * (1.0 - iou[1]).detach() * weight).sum() / target_scores_sum
            (1.0 - iou[1])åˆ™æ˜¯æ”¹è¿›çš„focal eiou è¿™é‡Œé€‰æ‹©äº†æŒ–æ˜å›°éš¾æ ·æœ¬
            
            å¦‚æœæ˜¯ä¸‹é¢è¿™ä¸ªå°±æ˜¯åŸæœ¬çš„focal eiouä»æ—§å…³æ³¨æ˜“åˆ†æ ·æœ¬
             loss_iou = ((1.0 - iou[0]) * iou[1].detach() * weight).sum() / target_scores_sum
        '''
        if type(iou) is tuple:
            loss_iou = ((1.0 - iou[0]) * iou[1].detach() * weight).sum() / target_scores_sum
        else:
            loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum

        # DFL loss
        if self.use_dfl:
            target_ltrb = bbox2dist(anchor_points, target_bboxes, self.reg_max)
            loss_dfl = self._df_loss(pred_dist[fg_mask].view(-1, self.reg_max + 1), target_ltrb[fg_mask]) * weight
            loss_dfl = loss_dfl.sum() / target_scores_sum
        else:
            loss_dfl = torch.tensor(0.0).to(pred_dist.device)

        return loss_iou, loss_dfl




    @staticmethod
    def _df_loss(pred_dist, target):
        # Return sum of left and right DFL losses
        # Distribution Focal Loss (DFL) proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391
        tl = target.long()  # target left
        tr = tl + 1  # target right
        wl = tr - target  # weight left
        wr = 1 - wl  # weight right
        return (F.cross_entropy(pred_dist, tl.view(-1), reduction='none').view(tl.shape) * wl +
                F.cross_entropy(pred_dist, tr.view(-1), reduction='none').view(tl.shape) * wr).mean(-1, keepdim=True)

